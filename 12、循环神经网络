循环神经网络(应该是解决前后数据有关联的序列)
目的是基于当前的输入与过去的输入序列，预测序列的下一个字符。
循环神经网络引入一个隐藏变量H，用Ht表示H在时间步t的值。Ht的计算基于Xt(当前输入)和Ht-1(前一时间步的隐藏变量值)
可以认为Ht记录了到当前字符为止的序列信息，利用Ht对序列的下一个字符进行预测。

循环神经网络的构造
假设Xt是时间步t的小批量输入，Ht是改时间步的隐藏变量，则： 
Ht = f(Xt*Wxh + Ht-1*Whh + bh)  
其中f()表示非线性激活函数，函数体内参数是当前输入和上一时间步隐藏变量的线性回归。 
Ht能够捕捉截至当前时间步的序列的历史信息，就像是神经网络当前时间步的状态或记忆一样。
由于Ht的计算基于Ht-1，上式的计算是循环的，使用循环计算的网络即循环神经网络(recurrent neural network).

在时间步t,输出层的输出为： Ot = Ht*Whq + bq  (就直接一个线性关系)

one-hot向量
将字符表示成向量，采用one-hot向量，每个字符对应长度为N的向量，根据字符索引在相对位置添加元素1，其余位置添加元素0.

我们每次采用的小批量的形状是（批量大小，时间步数），需要将这样的小批量变换成数个形状为（批量大小，词典大小）的矩阵，矩阵个数等于时间步数。
也就是说，时间步t的输入为Xt(n*d维)，其中n为批量大小，d为词向量大小，即one-hot向量长度(词典大小)

裁剪梯度
循环神经网络中较容易出现梯度衰减或梯度爆炸，这会导致网络几乎无法训练。
裁剪梯度(clip gradient)是一种应对梯度爆炸的方法。假设我们把所有模型参数的梯度拼接成一个向量g,并设裁剪的阈值是θ。
裁剪后的梯度的L2范数不超过θ
即通过阈值θ,来判断是否需要对原模型所有参数的梯度向量进行裁剪。

定义预测函数

困惑度
通常使用困惑度(perplexity)来评价语言模型的好坏，困惑度是对交叉熵损失函数做指数运算后得到的值。特别的，
在最佳情况下，模型总是把标签类别的概率预测为1，此时困惑度为1；
在最坏情况下，模型总是把标签类别的概率预测为0，此时困惑度为,正无穷；
基线情况下，模型总是预测所有类别的概率都相同，此时困惑度为类别个数。

显然，任何一个有效模型的困惑度必须小于类别个数。

定义模型训练函数
跟之前章节的模型训练函数相比，这里的模型训练函数有以下几点不同：
1、使用困惑度评价模型。
2、在迭代模型参数前裁剪梯度。
3、对时序数据采用不同采用方法将导致隐藏状态初始化的不同。

批量训练的过程中，参数是以批为单位更新的，每个批次内模型的参数都是一样的。
循环神经网络的参数数量与输入序列长度无关，而是根据定义的隐藏变量长度有关。

随机采样中每个样本只包含局部的时间序列信息，因为样本不完整所以每个批量需要重新初始化隐藏状态。
