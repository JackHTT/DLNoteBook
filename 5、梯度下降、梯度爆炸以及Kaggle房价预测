一、梯度消失和梯度爆炸
深度模型有关数值稳定性的典型问题是消失和爆炸

当神经网络的层数较多时，模型的数值稳定性容易变差。 比如权重过小或过大，那么经过多层之后输出值会非常大或非常小。此时梯度的计算会消失或爆炸。

二、随机初始化模型参数
随机初始化模型参数方法有很多，例如torch.nn.init.normal_(),而且pytorch中nn.Module的模块参数都采取了较为合理的初始化策略。

Xavier随机初始化
某全连接层输入个数为a,输出个数为b,Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布
   U(-sqrt(6/(a+b)),sqrt(6/(a+b)))
模型参数初始化后，每层输出的方差不该受某层输入个数的影响，且每层梯度的方差也不该受该层输出个数影响。

考虑环境因素
协变量偏移
假设，输入的分布可能随时间而改变，但是标记函数，即条件分布P(y|x)不会改变
标签偏移
概念偏移
