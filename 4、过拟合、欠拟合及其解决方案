一、训练误差和泛化误差
训练误差：模型在训练数据集上表现出的误差
泛化误差：模型在任意一个测试数据上表现出的误差的期望，常常通过测试数据集上的误差来近似
计算误差可使用平方损失函数或交叉熵损失函数
机器学习模型应该关注降低泛化误差

二、模型选择
验证数据集：从训练数据集中抽出用来进行模型选择和超参数调优。
K折交叉验证：当训练数据不够用时，预留大量的验证数据显得太奢侈。所以K折交叉验证是改善方法。
使用所有训练数据进行多次训练来达到降低过拟合的效果。

三、过拟合和欠拟合
欠拟合：模型无法得到较低的训练误差
过拟合：模型的训练误差远小于它在测试数据集上的误差。

模型复杂度
描述模型的复杂程度，往往模型越复杂越容易过拟合。

训练数据集大小
如果训练数据集中样本数过少，特别是比模型参数数量更少时，过拟合更容易发生。此外，泛化误差不会随训练数据集里样本数量增加而增加。
在计算资源允许范围内，我们通常希望训练数据集大一些。

解决办法：
1、权重衰减
等价于L2正则化
