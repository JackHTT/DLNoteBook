一、softmax的基本概念
1、针对多分类问题
对于一个三分类问题，用离散值表示各个类别，例如1、2、3等
2、softmax是单层神经网络，只有输入层和输出层，
三分类问题的输出层有三个神经元，分别表示输出值 oi 当作预测类别是 i 的置信度，输出值用权重矢量表示
同时值得注意的是网络的输出神经元即当前类别的置信度这个值的范围是没有限定的，通过比较得到最大的置信度从而得到模型的预测类别值
以上使用置信度存在的问题：
(1) 输出值的大小范围不确定，所以没有实际的表示意义。
(2) 输出是离散值，无法衡量预测值和真实值之间的误差
为此引出了softmax运算符：
y1,y2,y3=softmax(o1,o2,o3)
其中y1 = exp(o1)/(exp(o1)+exp(o2)+exp(o3)),y2,y3同理
这样输出值就转化为了0~1之间的概率值

总的计算表达公式： 
O = XW + b, 
Y = softmax(O),

针对softmax运算符，系统的真实值同时需要做一定的调整，真实类别设为1，其余类别为0

如果继续使用平方损失函数，那么会过于苛刻，针对分类正确情况时，预测概率值不同还是会导致误差的忽大忽小，所以提出了新的损失函数。
衡量两个概率分布差异的测量函数：交叉熵损失函数
H(y,pred) = -y*log(pred)
由于一个label向量中一个元素为1，其余元素为0，所以交叉熵函数只含有一项，它只关注对正确类别的预测概率，因为只要其值足够大就可以保证分类正确
loss = 所有样本交叉熵的平均数
