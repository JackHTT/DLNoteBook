一、线性回归基本要素
1、模型
  用向量表示的线性模型，针对每条训练集样本的n个特征可得到表达式：
      y = w*x + b
  其中x表示每条样本的特征向量，y表示label值，w表示各特征的权重系数，b表示偏置系数
2、损失函数
  衡量预测值和真实值之间的误差,常用的有平方函数，表达式为：
      L(w,b) = 1/n * 误差的平方和
  其中n表示训练集中样本的总个数
3、优化函数
  针对求解最优的模型参数问题，目标是使损失函数最小化，最直接的方法是用损失函数L(w,b)对w和b求偏导，然后取导数为0的参数值，这种被称为解析解。
  但是由于损失函数的复杂性以及求解析解运算量过大，所以往往会求解数值解，
  数值解是通过迭代的方法，一步步让损失函数变小，直到达到设定的期望的误差值而停止迭代。
  常用的模型最优参数求解方法有随机梯度下降（SGD），批量梯度下降等等。
  w,b在指定的学习率下朝梯度下降的方向不断迭代直至损失函数达到最小值（或者说不再下降）
  随机梯度下降有可能会找到局部最优值的参数
